# [icml16-reinforcement](http://icml.cc/2016/?page_id=1649 "ICML 2016 Accepted Papers")



### 1 Inverse Optimal Control with Deep Networks via Policy Optimization
Chelsea Finn, UC Berkeley; Sergey Levine, ; Pieter Abbeel, Berkeley



### 2 Accurate Robust and Efficient Error Estimation for Decision Trees
Lixin Fan, Nokia Technologies



### 3 Structure Learning of Partitioned Markov Networks
Song Liu, The Inst. of Stats. Math.; Taiji Suzuki, ; Masashi Sugiyama, University of Tokyo; Kenji ,



### 4 Doubly Robust Off-policy Value Evaluation for Reinforcement Learning
Nan Jiang, University of Michigan; Lihong Li, Microsoft



### 5 Anytime Exploration for Multi-armed Bandits using Confidence Information
Kwang-Sung Jun, UW-Madison; Robert Nowak,



### 6 Markov Latent Feature Models
Aonan Zhang, Columbia University; John Paisley,



### 7 The Knowledge Gradient for Sequential Decision Making with Stochastic Binary Feedbacks
Yingfei Wang, Princeton University; Chu Wang, ; Warren Powell,



### 8 Learning to Filter with Predictive State Inference Machines
Wen Sun, Carnegie Mellon University; Arun Venkatraman, Carnegie Mellon University; Byron Boots, ; J.Andrew Bagnell, Carnegie Mellon University



### 9 Benchmarking Deep Reinforcement Learning for Continuous Control
Yan Duan, University of California, Berk; Xi Chen, University of California, Berkeley; Rein Houthooft, Ghent University; John Schulman, University of California, Berkeley; Pieter Abbeel, Berkeley



### 10 Cumulative Prospect Theory Meets Reinforcement Learning: Prediction and Control
Prashanth L.A., University of Maryland ; Cheng Jie, University of Maryland – College Park; Michael Fu, University of Maryland – College Park; Steve Marcus, University of Maryland – College Park; Csaba Szepesvari, Alberta



### 11 ForecastICU: A Prognostic Decision Support System for Timely Prediction of Intensive Care Unit Admission
Jinsung Yoon, University of California, Los ; Ahmed Alaa, University of California, Los Angeles; Scott Hu, University of California, Los Angeles; Mihaela van der Schaar,



### 12 Sequential decision making under uncertainty: Are most decisions easy?
Ozgur Simsek, ; Simon Algorta, ; Amit Kothiyal,



### 13 Opponent Modeling in Deep Reinforcement Learning
He He, ; Jordan , ; Hal Daume, Maryland



### 14 Softened Approximate Policy Iteration for Markov Games
Julien Pérolat, Univ. Lille; Bilal Piot, Univ. Lille; Matthieu Geist, ; Bruno Scherrer, ; Olivier Pietquin, Univ. Lille, CRIStAL, UMR 9189, SequeL Team, Villeneuve d’Ascq, 59650, FRANCE



### 15 Asynchronous Methods for Deep Reinforcement Learning
Volodymyr Mnih, Google DeepMind; Adria Puigdomenech Badia, Google DeepMind; Mehdi Mirza, ; Alex Graves, Google DeepMind; Timothy Lillicrap, Google DeepMind; Tim Harley, Google DeepMind; David , ; Koray Kavukcuoglu, Google Deepmind



### 16 Dueling Network Architectures for Deep Reinforcement Learning
Ziyu Wang, Google Inc.; Nando de Freitas, University of Oxford; Tom Schaul, Google Inc.; Matteo Hessel, Google Deepmind; Hado van Hasselt, Google DeepMind; Marc Lanctot, Google Deepmind



### 17 Differentially Private Policy Evaluation
Borja Balle, Lancaster University; Maziar Gomrokchi, McGill University; Doina Precup, McGill



### 18 Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning
Philip Thomas, CMU; Emma ,



### 19 Hierarchical Decision Making In Electricity Grid Management
Gal Dalal, Technion; Elad Gilboa, Technion; Shie Mannor, Technion



### 20 Efficient Multi-Instance Learning for Activity Recognition from Time Series Data Using an Auto-Regressive Hidden Markov Model
Xinze Guan, Oregon State University; Raviv Raich, Oregon State University; Weng-keen ,



### 21 Generalization and Exploration via Randomized Value Functions
Ian Osband, Stanford; Ben , ; Zheng Wen, Adobe Research



### 22 Interacting Particle Markov Chain Monte Carlo
Tom Rainforth, University of Oxford; Christian Naesseth, Linköping University; Brooks Paige, University of Oxford; Frank Wood, ; Jan-Willem Vandemeent, ; Fredrik Lindsten, Uppsala University



### 23 Meta–Gradient Boosted Decision Tree Model for Weight and Target Learning
Yury Ustinovskiy, Yandex; Valentina Fedorova, Yandex; Gleb Gusev, Yandex; Pavel Serdyukov, Yandex



### 24 Model-Free Imitation Learning with Policy Optimization
Jonathan Ho, Stanford; Jayesh Gupta, Stanford University; Stefano Ermon,



### 25 Memory-based Control of Active Perception and Action in Minecraft
Junhyuk Oh, University of Michigan; Valliappa Chockalingam, University of Michigan; Satinder , ; Honglak Lee, University of Michigan



### 26 Improving the Efficiency of Deep Reinforcement Learning with Normalized Advantage Functions and Synthetic Experience
Shixiang Gu, University of Cambridge; Sergey Levine, Google; Timothy Lillicrap, Google DeepMind; Ilya Sutskever, OpenAI



### 27 Near Optimal Behavior via Approximate State Abstraction
David Abel, Brown University; David Hershkowitz, Brown University; Michael Littman,



### 28 Model-Free Trajectory Optimization for Reinforcement Learning of Motor Skills
Riad Akrour, TU Darmstadt; Gerhard Neumann,



